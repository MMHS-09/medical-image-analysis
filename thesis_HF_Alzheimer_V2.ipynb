{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9b4d82",
   "metadata": {},
   "source": [
    "# Kernel Attention Network (KAN) for Brain Tumor Classification\n",
    "\n",
    "Implementation of KAN architecture with proper feature extraction and attention mechanisms for MRI image analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f09379",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies\n",
    "\n",
    "Import required libraries and modules for implementing KAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c175f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8335a57",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "Setup data pipelines with proper transforms for MRI images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f4fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 4\n",
      "Training samples: 13927\n",
      "Testing samples:  3961\n"
     ]
    }
   ],
   "source": [
    "# Data directories\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((224, 224)),                # Resize for backbone\n",
    "    transforms.ToTensor(),                        # Convert to tensor\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Repeat grayscale to 3 channels\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])   # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(TEST_DIR,  transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                         num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Testing samples:  {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e755938",
   "metadata": {},
   "source": [
    "## 3. Define KAN Architecture\n",
    "\n",
    "Implement the Kernel Attention Network model with proper feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b481ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelAttention(nn.Module):\n",
    "    def __init__(self, in_dim, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_dim, in_dim, kernel_size=kernel_size, \n",
    "                             padding=kernel_size//2, groups=in_dim)\n",
    "        self.spatial_gate = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Local feature aggregation\n",
    "        local_feat = self.conv(x)\n",
    "        # Generate attention weights\n",
    "        attn = self.spatial_gate(local_feat)\n",
    "        return x * attn\n",
    "\n",
    "class KANModel(nn.Module):\n",
    "    def __init__(self, num_classes, backbone='resnet18'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Feature Extraction Backbone\n",
    "        if backbone == 'resnet18':\n",
    "            base = models.resnet18(pretrained=True)\n",
    "            self.feature_dim = 512\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
    "            \n",
    "        # Remove the final FC layer\n",
    "        self.features = nn.Sequential(*list(base.children())[:-2])\n",
    "        \n",
    "        # 2. Kernel Attention Module\n",
    "        self.attention = KernelAttention(self.feature_dim)\n",
    "        \n",
    "        # 3. Global Average Pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # 4. Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        x = self.features(x)  # [B, 512, H', W']\n",
    "        \n",
    "        # Apply kernel attention\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.gap(x)      # [B, 512, 1, 1]\n",
    "        x = x.view(x.size(0), -1)  # [B, 512]\n",
    "        \n",
    "        # Classification\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c6802",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "Setup training parameters and optimization configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbcdfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = KANModel(num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler (removed verbose parameter)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409394b9",
   "metadata": {},
   "source": [
    "## 5. Training and Evaluation Loop\n",
    "\n",
    "Implement the main training loop with evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0bca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [-1:59:30<00:00, -14.31it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:03<00:00, 37.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Train Loss: 0.2162, Train Acc: 0.9273\n",
      "Val Loss: 0.1920, Val Acc: 0.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [00:15<00:00, 27.86it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 41.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 0.0448, Train Acc: 0.9850\n",
      "Val Loss: 0.2281, Val Acc: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [01:03<00:00,  6.88it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [-1:59:16<00:00, -2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0278, Train Acc: 0.9911\n",
      "Val Loss: 0.1626, Val Acc: 0.9664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [00:15<00:00, 27.93it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0270, Train Acc: 0.9913\n",
      "Val Loss: 0.1982, Val Acc: 0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [00:15<00:00, 28.27it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 51.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0144, Train Acc: 0.9955\n",
      "Val Loss: 0.1915, Val Acc: 0.9692\n",
      "\n",
      "Validation Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       1.00      0.93      0.96      1208\n",
      "meningioma_tumor       0.93      0.99      0.96       930\n",
      "        no_tumor       0.95      1.00      0.97       831\n",
      " pituitary_tumor       0.99      0.98      0.98       992\n",
      "\n",
      "        accuracy                           0.97      3961\n",
      "       macro avg       0.97      0.97      0.97      3961\n",
      "    weighted avg       0.97      0.97      0.97      3961\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [01:03<00:00,  6.90it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [-1:59:15<00:00, -2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0200, Train Acc: 0.9943\n",
      "Val Loss: 0.2150, Val Acc: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [00:15<00:00, 28.32it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0160, Train Acc: 0.9950\n",
      "Val Loss: 0.1916, Val Acc: 0.9674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [00:15<00:00, 28.04it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 51.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0128, Train Acc: 0.9961\n",
      "Val Loss: 0.2205, Val Acc: 0.9712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [00:15<00:00, 28.19it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 52.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0082, Train Acc: 0.9972\n",
      "Val Loss: 0.2349, Val Acc: 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 436/436 [00:15<00:00, 28.15it/s]\n",
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 50.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0166, Train Acc: 0.9950\n",
      "Val Loss: 0.1996, Val Acc: 0.9702\n",
      "\n",
      "Validation Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.99      0.94      0.96      1208\n",
      "meningioma_tumor       0.94      0.97      0.96       930\n",
      "        no_tumor       0.96      1.00      0.98       831\n",
      " pituitary_tumor       0.98      0.99      0.98       992\n",
      "\n",
      "        accuracy                           0.97      3961\n",
      "       macro avg       0.97      0.97      0.97      3961\n",
      "    weighted avg       0.97      0.97      0.97      3961\n",
      "\n",
      "\n",
      "Loading best model for final evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 124/124 [00:02<00:00, 52.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Results:\n",
      "Test Accuracy: 0.9712\n",
      "\n",
      "Detailed Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.99      0.93      0.96      1208\n",
      "meningioma_tumor       0.94      0.99      0.96       930\n",
      "        no_tumor       0.95      1.00      0.97       831\n",
      " pituitary_tumor       0.99      0.98      0.99       992\n",
      "\n",
      "        accuracy                           0.97      3961\n",
      "       macro avg       0.97      0.97      0.97      3961\n",
      "    weighted avg       0.97      0.97      0.97      3961\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Compute epoch metrics\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Compute metrics\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, \n",
    "                                target_names=train_dataset.classes)\n",
    "    \n",
    "    return avg_loss, accuracy, report\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Training phase\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, \n",
    "                                      optimizer, device)\n",
    "    \n",
    "    # Evaluation phase\n",
    "    val_loss, val_acc, val_report = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'kan_best_model.pth')\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Print detailed validation report every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"\\nValidation Report:\")\n",
    "        print(val_report)\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nLoading best model for final evaluation...\")\n",
    "model.load_state_dict(torch.load('kan_best_model.pth'))\n",
    "test_loss, test_acc, test_report = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"\\nFinal Test Results:\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b2b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
