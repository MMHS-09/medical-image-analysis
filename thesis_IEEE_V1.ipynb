{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T17:02:40.311577Z",
     "iopub.status.busy": "2025-05-19T17:02:40.311333Z",
     "iopub.status.idle": "2025-05-19T17:02:51.829191Z",
     "shell.execute_reply": "2025-05-19T17:02:51.828647Z",
     "shell.execute_reply.started": "2025-05-19T17:02:40.311558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T16:16:09.074736Z",
     "iopub.status.busy": "2025-05-19T16:16:09.074366Z",
     "iopub.status.idle": "2025-05-19T16:16:46.680386Z",
     "shell.execute_reply": "2025-05-19T16:16:46.679389Z",
     "shell.execute_reply.started": "2025-05-19T16:16:09.074716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ─── 1. Paths ────────────────────────────────────────────────────────────────\n",
    "# DATA_DIR = \"/kaggle/input/brain-tumour\"\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "# ─── 2. Base Transform (no normalization) ──────────────────────────────────\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),            # scales to [0,1], shape [C,H,W]\n",
    "])\n",
    "\n",
    "# ─── 3. Create intermediate loaders to compute stats ──────────────────────\n",
    "train_ds_raw = datasets.ImageFolder(root=TRAIN_DIR, transform=base_transform)\n",
    "test_ds_raw  = datasets.ImageFolder(root=TEST_DIR,  transform=base_transform)\n",
    "\n",
    "train_loader_raw = DataLoader(train_ds_raw, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader_raw  = DataLoader(test_ds_raw,  batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# ─── 4. Helper to compute mean & std ───────────────────────────────────────\n",
    "def compute_mean_std(loader):\n",
    "    channel_sum   = torch.zeros(3)\n",
    "    channel_sqsum = torch.zeros(3)\n",
    "    num_pixels    = 0\n",
    "\n",
    "    for imgs, _ in loader:\n",
    "        # imgs: [B,3,H,W]\n",
    "        B, C, H, W = imgs.shape\n",
    "        num_pixels += B * H * W\n",
    "\n",
    "        channel_sum   += imgs.sum(dim=[0,2,3])\n",
    "        channel_sqsum += (imgs ** 2).sum(dim=[0,2,3])\n",
    "\n",
    "    mean = channel_sum / num_pixels\n",
    "    # E[x^2] - (E[x])^2\n",
    "    var  = (channel_sqsum / num_pixels) - (mean ** 2)\n",
    "    std  = torch.sqrt(var)\n",
    "\n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "train_mean, train_std = compute_mean_std(train_loader_raw)\n",
    "test_mean,  test_std  = compute_mean_std(test_loader_raw)\n",
    "\n",
    "print(\"Train mean:\", train_mean)\n",
    "print(\"Train std: \", train_std)\n",
    "print(\"Test mean: \", test_mean)\n",
    "print(\"Test std:  \", test_std)\n",
    "\n",
    "# ─── 5. Define final transforms using computed stats ───────────────────────\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std),  # use train stats for test\n",
    "])\n",
    "\n",
    "# ─── 6. Reload datasets with normalization ─────────────────────────────────\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=TEST_DIR,  transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ─── 7. Quick Sanity Check ─────────────────────────────────────────────────\n",
    "print(\"Classes:\", train_dataset.classes)\n",
    "print(\"Class→idx mapping:\", train_dataset.class_to_idx)\n",
    "print(\"Num train samples:\", len(train_dataset))\n",
    "print(\"Num test samples: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-19T17:01:44.697Z",
     "iopub.execute_input": "2025-05-19T16:16:46.681831Z",
     "iopub.status.busy": "2025-05-19T16:16:46.681472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Point to your Training folder\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "\n",
    "# 2. Collect all image paths with labels\n",
    "image_paths = []\n",
    "for label in os.listdir(TRAIN_DIR):\n",
    "    label_dir = os.path.join(TRAIN_DIR, label)\n",
    "    if os.path.isdir(label_dir):\n",
    "        for fname in os.listdir(label_dir):\n",
    "            if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                image_paths.append((os.path.join(label_dir, fname), label))\n",
    "\n",
    "# 3. Randomly sample 4 images\n",
    "sample_paths = random.sample(image_paths, 4)\n",
    "\n",
    "# 4. Plot them\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "for ax, (img_path, label) in zip(axes, sample_paths):\n",
    "    img = Image.open(img_path).convert('L')  # grayscale\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(label)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from PIL import Image\n",
    "\n",
    "# ——— Manual GLCM implementation with overflow‐safe bins ———\n",
    "def compute_glcm_features(arr, levels=8):\n",
    "    # make sure min_val/max_val are Python scalars, not uint8\n",
    "    min_val = int(arr.min())\n",
    "    max_val = int(arr.max())\n",
    "    # now no overflow when adding 1\n",
    "    bins = np.linspace(min_val, max_val + 1, levels + 1)\n",
    "\n",
    "    # quantize to 0…levels-1, then clip\n",
    "    arr_q = np.digitize(arr, bins) - 1\n",
    "    arr_q = np.clip(arr_q, 0, levels - 1)\n",
    "\n",
    "    H, W = arr_q.shape\n",
    "    glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "\n",
    "    # horizontal co-occurrences\n",
    "    for i in range(H):\n",
    "        for j in range(W - 1):\n",
    "            a = arr_q[i, j]\n",
    "            b = arr_q[i, j + 1]\n",
    "            glcm[a, b] += 1\n",
    "\n",
    "    # symmetrize\n",
    "    glcm = glcm + glcm.T\n",
    "\n",
    "    total = glcm.sum()\n",
    "    P = glcm / total if total > 0 else glcm\n",
    "\n",
    "    i_inds, j_inds = np.indices(P.shape)\n",
    "    contrast      = ((i_inds - j_inds)**2 * P).sum()\n",
    "    dissimilarity = (np.abs(i_inds - j_inds) * P).sum()\n",
    "    homogeneity   = (P / (1.0 + np.abs(i_inds - j_inds))).sum()\n",
    "    ASM           = (P**2).sum()\n",
    "    energy        = np.sqrt(ASM)\n",
    "\n",
    "    mu_i    = (i_inds * P).sum()\n",
    "    mu_j    = (j_inds * P).sum()\n",
    "    sigma_i = np.sqrt(((i_inds - mu_i)**2 * P).sum())\n",
    "    sigma_j = np.sqrt(((j_inds - mu_j)**2 * P).sum())\n",
    "\n",
    "    denom = sigma_i * sigma_j\n",
    "    correlation = (((i_inds - mu_i)*(j_inds - mu_j) * P).sum()) / denom \\\n",
    "                  if denom > 0 else 0\n",
    "\n",
    "    return contrast, dissimilarity, homogeneity, energy, correlation, ASM\n",
    "\n",
    "# ——— Radiomics feature extractor ———\n",
    "def extract_radiomics(pil_img):\n",
    "    arr = np.array(pil_img, dtype=np.float64)\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr.mean(axis=2)          # RGB → gray\n",
    "    mn, mx = arr.min(), arr.max()\n",
    "    arr = (arr - mn) / (mx - mn) if mx > mn else arr\n",
    "\n",
    "    # first‐order\n",
    "    mean_intensity = arr.mean()\n",
    "    std_intensity  = arr.std()\n",
    "    skewness       = skew(arr.flatten())\n",
    "    kurt_val       = kurtosis(arr.flatten())\n",
    "\n",
    "    # texture via GLCM (8 levels)\n",
    "    uint8_img = (arr * 255).astype(np.uint8)\n",
    "    glcm_feats = compute_glcm_features(uint8_img, levels=8)\n",
    "\n",
    "    # frequency\n",
    "    fft_mag   = np.abs(np.fft.fftshift(np.fft.fft2(arr)))\n",
    "    freq_mean = fft_mag.mean()\n",
    "    freq_std  = fft_mag.std()\n",
    "\n",
    "    return [\n",
    "        mean_intensity, std_intensity, skewness, kurt_val,\n",
    "        *glcm_feats,   # contrast, dissimilarity, homogeneity, energy, correlation, ASM\n",
    "        freq_mean, freq_std\n",
    "    ]\n",
    "\n",
    "# ——— Example on your HuggingFace dataset ———\n",
    "if __name__ == \"__main__\":\n",
    "    # assume `ds` is already loaded; e.g. via `datasets.load_dataset(...)`\n",
    "    # s = ds[\"train\"][0]\n",
    "    # img = s[\"image\"]    # PIL.Image\n",
    "\n",
    "    img = Image.open(\"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing/glioma_tumor/1879.png\")\n",
    "\n",
    "    arr = np.array(img)\n",
    "    print(f\"Image shape: {arr.shape}, dtype: {arr.dtype}\")\n",
    "    print(f\"Value range: {arr.min()}–{arr.max()}\")\n",
    "\n",
    "    feature_names = [\n",
    "        \"mean_intensity\",\"std_intensity\",\"skewness\",\"kurtosis\",\n",
    "        \"contrast\",\"dissimilarity\",\"homogeneity\",\"energy\",\n",
    "        \"correlation\",\"ASM\",\"freq_mean\",\"freq_std\"\n",
    "    ]\n",
    "    feats = extract_radiomics(img)\n",
    "\n",
    "    print(\"\\nRadiomic features:\")\n",
    "    for name, val in zip(feature_names, feats):\n",
    "        print(f\" • {name}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T15:32:59.722985Z",
     "iopub.status.busy": "2025-05-19T15:32:59.722269Z",
     "iopub.status.idle": "2025-05-19T15:55:25.856277Z",
     "shell.execute_reply": "2025-05-19T15:55:25.855064Z",
     "shell.execute_reply.started": "2025-05-19T15:32:59.722954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from PIL import Image\n",
    "\n",
    "# TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "# TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "# # Mapping from class name to integer label\n",
    "# label_map = {\n",
    "#     \"glioma_tumor\": 0,\n",
    "#     \"meningioma_tumor\": 1,\n",
    "#     \"no_tumor\": 2,\n",
    "#     \"pituitary_tumor\": 3\n",
    "# }\n",
    "\n",
    "# # ——— Manual GLCM implementation with overflow‑safe bins ———\n",
    "# def compute_glcm_features(arr, levels=8):\n",
    "#     min_val = int(arr.min())\n",
    "#     max_val = int(arr.max())\n",
    "#     bins = np.linspace(min_val, max_val + 1, levels + 1)\n",
    "#     arr_q = np.clip(np.digitize(arr, bins) - 1, 0, levels - 1)\n",
    "#     H, W = arr_q.shape\n",
    "#     glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "#     for i in range(H):\n",
    "#         for j in range(W - 1):\n",
    "#             glcm[arr_q[i, j], arr_q[i, j + 1]] += 1\n",
    "#     glcm = glcm + glcm.T\n",
    "#     total = glcm.sum()\n",
    "#     P = glcm / total if total > 0 else glcm\n",
    "#     i_inds, j_inds = np.indices(P.shape)\n",
    "#     contrast      = ((i_inds - j_inds)**2 * P).sum()\n",
    "#     dissimilarity = (np.abs(i_inds - j_inds) * P).sum()\n",
    "#     homogeneity   = (P / (1.0 + np.abs(i_inds - j_inds))).sum()\n",
    "#     ASM           = (P**2).sum()\n",
    "#     energy        = np.sqrt(ASM)\n",
    "#     mu_i    = (i_inds * P).sum()\n",
    "#     mu_j    = (j_inds * P).sum()\n",
    "#     sigma_i = np.sqrt(((i_inds - mu_i)**2 * P).sum())\n",
    "#     sigma_j = np.sqrt(((j_inds - mu_j)**2 * P).sum())\n",
    "#     denom = sigma_i * sigma_j\n",
    "#     correlation = (((i_inds - mu_i)*(j_inds - mu_j) * P).sum()) / denom if denom > 0 else 0\n",
    "#     return contrast, dissimilarity, homogeneity, energy, correlation, ASM\n",
    "\n",
    "# # ——— Radiomics feature extractor ———\n",
    "# def extract_radiomics(pil_img):\n",
    "#     arr = np.array(pil_img, dtype=np.float64)\n",
    "#     if arr.ndim == 3:\n",
    "#         arr = arr.mean(axis=2)\n",
    "#     mn, mx = arr.min(), arr.max()\n",
    "#     arr = (arr - mn) / (mx - mn) if mx > mn else arr\n",
    "#     mean_intensity = arr.mean()\n",
    "#     std_intensity  = arr.std()\n",
    "#     skewness       = skew(arr.flatten())\n",
    "#     kurt_val       = kurtosis(arr.flatten())\n",
    "#     uint8_img = (arr * 255).astype(np.uint8)\n",
    "#     glcm_feats = compute_glcm_features(uint8_img, levels=8)\n",
    "#     fft_mag   = np.abs(np.fft.fftshift(np.fft.fft2(arr)))\n",
    "#     freq_mean = fft_mag.mean()\n",
    "#     freq_std  = fft_mag.std()\n",
    "#     return [\n",
    "#         mean_intensity, std_intensity, skewness, kurt_val,\n",
    "#         *glcm_feats,\n",
    "#         freq_mean, freq_std\n",
    "#     ]\n",
    "\n",
    "# def load_radiomics_from_dir(base_dir):\n",
    "#     X, y = [], []\n",
    "#     classes = sorted(os.listdir(base_dir))\n",
    "#     for label in classes:\n",
    "#         class_dir = os.path.join(base_dir, label)\n",
    "#         if not os.path.isdir(class_dir):\n",
    "#             continue\n",
    "#         for fname in os.listdir(class_dir):\n",
    "#             if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\", \".bmp\")):\n",
    "#                 continue\n",
    "#             path = os.path.join(class_dir, fname)\n",
    "#             try:\n",
    "#                 img = Image.open(path).convert(\"RGB\")\n",
    "#                 feats = extract_radiomics(img)\n",
    "#                 X.append(feats)\n",
    "#                 y.append(label_map[label])  # map string to integer\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Skipped {path}: {e}\")\n",
    "#     return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load train\n",
    "#     X_train, y_train = load_radiomics_from_dir(TRAIN_DIR)\n",
    "#     print(f\"Loaded {len(y_train)} training samples, feature vector length = {X_train.shape[1]}\")\n",
    "#     # Load test\n",
    "#     X_test, y_test = load_radiomics_from_dir(TEST_DIR)\n",
    "#     print(f\"Loaded {len(y_test)} testing samples, feature vector length = {X_test.shape[1]}\")\n",
    "#     # Save to .npz\n",
    "#     np.savez(\n",
    "#         \"radiomics_dataset.npz\",\n",
    "#         X_train=X_train,\n",
    "#         y_train=y_train,\n",
    "#         X_test=X_test,\n",
    "#         y_test=y_test\n",
    "#     )\n",
    "#     print(\"Saved radiomics_dataset.npz with integer labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"radiomics_dataset.npz\", allow_pickle=True)\n",
    "X_train, y_train = data[\"X_train\"], data[\"y_train\"]\n",
    "X_test,  y_test  = data[\"X_test\"],  data[\"y_test\"]\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape:  {X_test.shape}, y_test shape:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T16:22:16.907044Z",
     "iopub.status.busy": "2025-05-19T16:22:16.906196Z",
     "iopub.status.idle": "2025-05-19T16:22:16.935972Z",
     "shell.execute_reply": "2025-05-19T16:22:16.935157Z",
     "shell.execute_reply.started": "2025-05-19T16:22:16.907016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Load the .npz file\n",
    "rad = np.load('/home/mhs/thesis/radiomics_dataset.npz')\n",
    "\n",
    "# 2. Extract train/test splits\n",
    "X_train_rad, y_train = rad['X_train'], rad['y_train']\n",
    "X_test_rad,  y_test  = rad['X_test'],  rad['y_test']\n",
    "\n",
    "# 3. (Optional) Inspect shapes\n",
    "print(\"X_train_rad shape:\", X_train_rad.shape)\n",
    "print(\"y_train shape:   \", y_train.shape)\n",
    "print(\"X_test_rad shape: \", X_test_rad.shape)\n",
    "print(\"y_test shape:    \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T16:29:33.244548Z",
     "iopub.status.busy": "2025-05-19T16:29:33.244249Z",
     "iopub.status.idle": "2025-05-19T16:29:35.729684Z",
     "shell.execute_reply": "2025-05-19T16:29:35.728671Z",
     "shell.execute_reply.started": "2025-05-19T16:29:33.244527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the .npz file\n",
    "rad = np.load('/home/mhs/thesis/radiomics_dataset.npz')\n",
    "\n",
    "# 2. Extract train/test splits\n",
    "X_train_rad, y_train = rad['X_train'], rad['y_train']\n",
    "X_test_rad,  y_test  = rad['X_test'],  rad['y_test']\n",
    "\n",
    "# 3. (Optional) Inspect shapes\n",
    "print(\"X_train_rad shape:\", X_train_rad.shape)\n",
    "print(\"y_train shape:   \", y_train.shape)\n",
    "print(\"X_test_rad shape: \", X_test_rad.shape)\n",
    "print(\"y_test shape:    \", y_test.shape)\n",
    "\n",
    "\n",
    "# --- 2) Radiomics-only classifiers ---\n",
    "# a) Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_rad, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test_rad)\n",
    "print(\"Random Forest on radiomics only:\")\n",
    "print(\"  Test Acc:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "xg = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xg.fit(X_train_rad, y_train)\n",
    "y_pred_rf = xg.predict(X_test_rad)\n",
    "print(\"XGBoost on radiomics only:\")\n",
    "print(\"  Test Acc:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pykan pytorch-tabnet torch scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pykan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_rad shape: (13927, 12)\n",
      "y_train shape:    (13927,)\n",
      "X_test_rad shape:  (3961, 12)\n",
      "y_test shape:     (3961,)\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KAN Training: 100%|██████████| 100/100 [01:19<00:00,  1.26it/s]\n",
      "/home/mhs/miniforge3/envs/thesis/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN on radiomics only:\n",
      "  Test Acc: 0.4165614743751578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.82      0.58      1208\n",
      "           1       0.36      0.31      0.33       930\n",
      "           2       0.83      0.17      0.28       831\n",
      "           3       0.29      0.23      0.26       992\n",
      "\n",
      "    accuracy                           0.42      3961\n",
      "   macro avg       0.48      0.38      0.36      3961\n",
      "weighted avg       0.47      0.42      0.38      3961\n",
      "\n",
      "epoch 0  | loss: 1.45014 | test_accuracy: 0.29841 |  0:00:00s\n",
      "epoch 1  | loss: 1.0384  | test_accuracy: 0.33754 |  0:00:01s\n",
      "epoch 2  | loss: 0.94764 | test_accuracy: 0.20298 |  0:00:01s\n",
      "epoch 3  | loss: 0.90773 | test_accuracy: 0.18581 |  0:00:01s\n",
      "epoch 4  | loss: 0.87215 | test_accuracy: 0.28427 |  0:00:49s\n",
      "epoch 5  | loss: 0.83824 | test_accuracy: 0.29891 |  0:00:02s\n",
      "epoch 6  | loss: 0.8281  | test_accuracy: 0.3176  |  0:00:02s\n",
      "epoch 7  | loss: 0.81142 | test_accuracy: 0.36354 |  0:00:03s\n",
      "epoch 8  | loss: 0.80229 | test_accuracy: 0.38627 |  0:00:03s\n",
      "epoch 9  | loss: 0.78904 | test_accuracy: 0.40621 |  0:00:03s\n",
      "epoch 10 | loss: 0.78283 | test_accuracy: 0.42641 |  0:00:04s\n",
      "epoch 11 | loss: 0.77367 | test_accuracy: 0.44837 |  0:00:04s\n",
      "epoch 12 | loss: 0.77433 | test_accuracy: 0.42843 |  0:00:04s\n",
      "epoch 13 | loss: 0.77263 | test_accuracy: 0.45241 |  0:00:05s\n",
      "epoch 14 | loss: 0.77134 | test_accuracy: 0.46049 |  0:00:05s\n",
      "epoch 15 | loss: 0.76713 | test_accuracy: 0.47084 |  0:00:05s\n",
      "epoch 16 | loss: 0.75654 | test_accuracy: 0.48851 |  0:00:06s\n",
      "epoch 17 | loss: 0.74698 | test_accuracy: 0.48649 |  0:00:06s\n",
      "epoch 18 | loss: 0.74264 | test_accuracy: 0.49987 |  0:00:06s\n",
      "epoch 19 | loss: 0.74247 | test_accuracy: 0.49407 |  0:00:07s\n",
      "epoch 20 | loss: 0.73558 | test_accuracy: 0.51199 |  0:00:07s\n",
      "epoch 21 | loss: 0.72564 | test_accuracy: 0.47084 |  0:00:07s\n",
      "epoch 22 | loss: 0.71958 | test_accuracy: 0.48321 |  0:00:08s\n",
      "epoch 23 | loss: 0.71609 | test_accuracy: 0.51729 |  0:00:08s\n",
      "epoch 24 | loss: 0.70867 | test_accuracy: 0.49457 |  0:00:08s\n",
      "epoch 25 | loss: 0.70126 | test_accuracy: 0.46453 |  0:00:09s\n",
      "epoch 26 | loss: 0.70353 | test_accuracy: 0.53168 |  0:00:09s\n",
      "epoch 27 | loss: 0.69882 | test_accuracy: 0.4928  |  0:00:09s\n",
      "epoch 28 | loss: 0.69582 | test_accuracy: 0.53926 |  0:00:10s\n",
      "epoch 29 | loss: 0.68616 | test_accuracy: 0.49255 |  0:00:10s\n",
      "epoch 30 | loss: 0.68779 | test_accuracy: 0.51325 |  0:00:10s\n",
      "epoch 31 | loss: 0.68624 | test_accuracy: 0.50795 |  0:00:11s\n",
      "epoch 32 | loss: 0.68252 | test_accuracy: 0.53547 |  0:00:11s\n",
      "epoch 33 | loss: 0.68082 | test_accuracy: 0.54456 |  0:00:11s\n",
      "epoch 34 | loss: 0.67206 | test_accuracy: 0.52865 |  0:00:59s\n",
      "epoch 35 | loss: 0.67406 | test_accuracy: 0.53774 |  0:00:12s\n",
      "epoch 36 | loss: 0.67581 | test_accuracy: 0.50189 |  0:00:12s\n",
      "epoch 37 | loss: 0.6757  | test_accuracy: 0.54203 |  0:00:13s\n",
      "epoch 38 | loss: 0.6682  | test_accuracy: 0.52562 |  0:00:13s\n",
      "epoch 39 | loss: 0.66679 | test_accuracy: 0.53749 |  0:00:14s\n",
      "epoch 40 | loss: 0.66346 | test_accuracy: 0.59429 |  0:00:14s\n",
      "epoch 41 | loss: 0.66948 | test_accuracy: 0.62661 |  0:00:15s\n",
      "epoch 42 | loss: 0.64952 | test_accuracy: 0.60086 |  0:00:15s\n",
      "epoch 43 | loss: 0.66005 | test_accuracy: 0.57864 |  0:00:16s\n",
      "epoch 44 | loss: 0.66158 | test_accuracy: 0.62661 |  0:00:16s\n",
      "epoch 45 | loss: 0.66704 | test_accuracy: 0.63292 |  0:00:17s\n",
      "epoch 46 | loss: 0.65544 | test_accuracy: 0.64883 |  0:00:17s\n",
      "epoch 47 | loss: 0.65256 | test_accuracy: 0.64352 |  0:00:18s\n",
      "epoch 48 | loss: 0.65624 | test_accuracy: 0.65665 |  0:00:18s\n",
      "epoch 49 | loss: 0.65661 | test_accuracy: 0.6771  |  0:00:19s\n",
      "epoch 50 | loss: 0.65113 | test_accuracy: 0.68139 |  0:00:19s\n",
      "epoch 51 | loss: 0.64466 | test_accuracy: 0.68796 |  0:00:20s\n",
      "epoch 52 | loss: 0.64763 | test_accuracy: 0.68139 |  0:00:20s\n",
      "epoch 53 | loss: 0.64769 | test_accuracy: 0.64428 |  0:00:21s\n",
      "epoch 54 | loss: 0.64194 | test_accuracy: 0.68468 |  0:00:21s\n",
      "epoch 55 | loss: 0.64592 | test_accuracy: 0.71447 |  0:00:22s\n",
      "epoch 56 | loss: 0.63756 | test_accuracy: 0.6872  |  0:00:22s\n",
      "epoch 57 | loss: 0.63757 | test_accuracy: 0.70058 |  0:00:23s\n",
      "epoch 58 | loss: 0.64005 | test_accuracy: 0.71194 |  0:00:23s\n",
      "epoch 59 | loss: 0.62416 | test_accuracy: 0.70285 |  0:00:24s\n",
      "epoch 60 | loss: 0.63253 | test_accuracy: 0.70386 |  0:00:24s\n",
      "epoch 61 | loss: 0.62919 | test_accuracy: 0.71472 |  0:00:25s\n",
      "epoch 62 | loss: 0.63013 | test_accuracy: 0.7026  |  0:00:25s\n",
      "epoch 63 | loss: 0.62929 | test_accuracy: 0.69957 |  0:00:26s\n",
      "epoch 64 | loss: 0.62865 | test_accuracy: 0.71926 |  0:00:27s\n",
      "epoch 65 | loss: 0.62558 | test_accuracy: 0.69705 |  0:00:27s\n",
      "epoch 66 | loss: 0.62173 | test_accuracy: 0.71371 |  0:00:28s\n",
      "epoch 67 | loss: 0.62809 | test_accuracy: 0.7233  |  0:00:28s\n",
      "epoch 68 | loss: 0.62306 | test_accuracy: 0.70689 |  0:00:29s\n",
      "epoch 69 | loss: 0.62145 | test_accuracy: 0.70538 |  0:00:29s\n",
      "epoch 70 | loss: 0.62465 | test_accuracy: 0.70891 |  0:00:30s\n",
      "epoch 71 | loss: 0.62237 | test_accuracy: 0.72053 |  0:00:30s\n",
      "epoch 72 | loss: 0.61945 | test_accuracy: 0.69629 |  0:00:31s\n",
      "epoch 73 | loss: 0.62772 | test_accuracy: 0.7175  |  0:00:31s\n",
      "epoch 74 | loss: 0.61574 | test_accuracy: 0.718   |  0:01:19s\n",
      "epoch 75 | loss: 0.60886 | test_accuracy: 0.72078 |  0:00:32s\n",
      "epoch 76 | loss: 0.61322 | test_accuracy: 0.70538 |  0:00:33s\n",
      "epoch 77 | loss: 0.61532 | test_accuracy: 0.71295 |  0:00:33s\n",
      "epoch 78 | loss: 0.61113 | test_accuracy: 0.6978  |  0:00:34s\n",
      "epoch 79 | loss: 0.61848 | test_accuracy: 0.71699 |  0:00:34s\n",
      "epoch 80 | loss: 0.61501 | test_accuracy: 0.72886 |  0:00:35s\n",
      "epoch 81 | loss: 0.61535 | test_accuracy: 0.6978  |  0:00:35s\n",
      "epoch 82 | loss: 0.60682 | test_accuracy: 0.72204 |  0:00:36s\n",
      "epoch 83 | loss: 0.60084 | test_accuracy: 0.71977 |  0:00:36s\n",
      "epoch 84 | loss: 0.60807 | test_accuracy: 0.70992 |  0:01:24s\n",
      "epoch 85 | loss: 0.60854 | test_accuracy: 0.71825 |  0:00:37s\n",
      "epoch 86 | loss: 0.60344 | test_accuracy: 0.71522 |  0:00:38s\n",
      "epoch 87 | loss: 0.61008 | test_accuracy: 0.7132  |  0:00:38s\n",
      "epoch 88 | loss: 0.60659 | test_accuracy: 0.71118 |  0:00:39s\n",
      "epoch 89 | loss: 0.60182 | test_accuracy: 0.72633 |  0:00:39s\n",
      "epoch 90 | loss: 0.60775 | test_accuracy: 0.7175  |  0:00:40s\n",
      "epoch 91 | loss: 0.60143 | test_accuracy: 0.7132  |  0:00:40s\n",
      "epoch 92 | loss: 0.59624 | test_accuracy: 0.73214 |  0:00:41s\n",
      "epoch 93 | loss: 0.59301 | test_accuracy: 0.72709 |  0:00:41s\n",
      "epoch 94 | loss: 0.59786 | test_accuracy: 0.71497 |  0:00:42s\n",
      "epoch 95 | loss: 0.59602 | test_accuracy: 0.73138 |  0:00:42s\n",
      "epoch 96 | loss: 0.60289 | test_accuracy: 0.72482 |  0:00:43s\n",
      "epoch 97 | loss: 0.59593 | test_accuracy: 0.72482 |  0:00:43s\n",
      "epoch 98 | loss: 0.58997 | test_accuracy: 0.70815 |  0:00:44s\n",
      "epoch 99 | loss: 0.59189 | test_accuracy: 0.73315 |  0:00:44s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_test_accuracy = 0.73315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhs/miniforge3/envs/thesis/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet on radiomics only:\n",
      "  Test Acc: 0.7331481949002777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71      1208\n",
      "           1       0.60      0.58      0.59       930\n",
      "           2       0.77      0.87      0.82       831\n",
      "           3       0.77      0.85      0.81       992\n",
      "\n",
      "    accuracy                           0.73      3961\n",
      "   macro avg       0.73      0.74      0.73      3961\n",
      "weighted avg       0.73      0.73      0.73      3961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from kan import KAN\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load the .npz file\n",
    "rad = np.load('/home/mhs/thesis/radiomics_dataset.npz')\n",
    "\n",
    "# 2. Extract train/test splits\n",
    "X_train_rad, y_train = rad['X_train'], rad['y_train']\n",
    "X_test_rad, y_test = rad['X_test'], rad['y_test']\n",
    "\n",
    "# 3. Inspect shapes\n",
    "print(\"X_train_rad shape:\", X_train_rad.shape)\n",
    "print(\"y_train shape:   \", y_train.shape)\n",
    "print(\"X_test_rad shape: \", X_test_rad.shape)\n",
    "print(\"y_test shape:    \", y_test.shape)\n",
    "\n",
    "# --- 2) Radiomics-only classifiers ---\n",
    "\n",
    "# a) KAN (Kolmogorov-Arnold Network)\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_rad, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_rad, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Initialize KAN model\n",
    "# Define the architecture: [input_dim, hidden_dim, output_dim]\n",
    "input_dim = X_train_rad.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "kan_model = KAN(width=[input_dim, 64, num_classes], grid=5, k=3)\n",
    "\n",
    "# Training function for KAN\n",
    "def train_kan(model, X, y, epochs=100, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"KAN Training\"):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Train KAN model\n",
    "train_kan(kan_model, X_train_tensor, y_train_tensor, epochs=100, lr=0.001)\n",
    "\n",
    "# Evaluate KAN model\n",
    "kan_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_kan = kan_model(X_test_tensor).argmax(dim=1).numpy()\n",
    "\n",
    "print(\"KAN on radiomics only:\")\n",
    "print(\"  Test Acc:\", accuracy_score(y_test, y_pred_kan))\n",
    "print(classification_report(y_test, y_pred_kan))\n",
    "\n",
    "# b) TabNet\n",
    "# Initialize TabNet model\n",
    "tabnet_clf = TabNetClassifier(\n",
    "    n_d=8,  # Dimension of the prediction layer\n",
    "    n_a=8,  # Dimension of the attention layer\n",
    "    n_steps=3,  # Number of steps in the architecture\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=0.02),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit TabNet model\n",
    "tabnet_clf.fit(\n",
    "    X_train=X_train_rad,\n",
    "    y_train=y_train,\n",
    "    eval_set=[(X_test_rad, y_test)],\n",
    "    eval_name=['test'],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=100,\n",
    "    patience=20,  # Early stopping after 20 epochs without improvement\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128\n",
    ")\n",
    "\n",
    "# Predict with TabNet\n",
    "y_pred_tabnet = tabnet_clf.predict(X_test_rad)\n",
    "\n",
    "print(\"TabNet on radiomics only:\")\n",
    "print(\"  Test Acc:\", accuracy_score(y_test, y_pred_tabnet))\n",
    "print(classification_report(y_test, y_pred_tabnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T17:03:04.392804Z",
     "iopub.status.busy": "2025-05-19T17:03:04.392158Z",
     "iopub.status.idle": "2025-05-19T17:05:52.918242Z",
     "shell.execute_reply": "2025-05-19T17:05:52.917333Z",
     "shell.execute_reply.started": "2025-05-19T17:03:04.392782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 0) Common imports\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ─── 1) Paths & Transforms ────────────────────────────────────────────\n",
    "# DATA_DIR  = \"/kaggle/input/brain-tumour\"\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "# # (Use your previously computed means & stds here)\n",
    "# train_mean = [0.32, 0.28, 0.30]\n",
    "# train_std  = [0.12, 0.11, 0.13]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# ─── 2) Datasets & Loaders ───────────────────────────────────────────\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=TEST_DIR,  transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
    "                          num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, \n",
    "                          num_workers=4, pin_memory=True)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# ─── 3) SimpleCNN Definition ─────────────────────────────────────────\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        # 224→112→56→28 after three pools\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*28*28, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "# ─── 4) Setup ─────────────────────────────────────────────────────────\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = SimpleCNN(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ─── 5) Training & Evaluation ────────────────────────────────────────\n",
    "for epoch in range(1, 11):\n",
    "    # -- train\n",
    "    model.train()\n",
    "    for imgs, lbls in train_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(imgs), lbls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # -- eval\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            preds = model(imgs).argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(lbls.numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Epoch {epoch:2d}/10 — Test Acc: {acc:.4f}\")\n",
    "\n",
    "# ─── 6) Final Report ───────────────────────────────────────────────────\n",
    "print(\"\\nFinal CNN classification report:\")\n",
    "print(classification_report(all_labels, all_preds, \n",
    "                            target_names=train_dataset.classes, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T17:07:45.752802Z",
     "iopub.status.busy": "2025-05-19T17:07:45.752237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ─── 1) Paths & MRI-specific normalization stats ───────────────────────────\n",
    "# DATA_DIR  = \"/kaggle/input/brain-tumour\"\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "# # (Use your previously computed means & stds here)\n",
    "# train_mean = [0.32, 0.28, 0.30]\n",
    "# train_std  = [0.12, 0.11, 0.13]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# ─── 3) Globals ────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# determine number of classes from your folder structure\n",
    "num_classes = len(next(os.walk(TRAIN_DIR))[1])\n",
    "\n",
    "# ─── 4) SimpleCNN with tunable dropout ────────────────────────────────────\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,  32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        # 224→112→56→28 after 3 pools\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ─── 5) Optuna objective ──────────────────────────────────────────────────\n",
    "def objective(trial):\n",
    "    # 5.1) Hyperparameters to tune\n",
    "    lr           = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.7)\n",
    "    batch_size   = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    momentum     = trial.suggest_float(\"momentum\", 0.5, 0.99)\n",
    "\n",
    "    # 5.2) DataLoaders with those batch sizes\n",
    "    train_loader = DataLoader(\n",
    "        datasets.ImageFolder(TRAIN_DIR, transform=train_transform),\n",
    "        batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        datasets.ImageFolder(TEST_DIR, transform=test_transform),\n",
    "        batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 5.3) Model, loss & optimizer\n",
    "    model     = SimpleCNN(num_classes, dropout_rate).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    # 5.4) Training loop (10 epochs)\n",
    "    for _ in range(10):\n",
    "        model.train()\n",
    "        for imgs, lbls in train_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(imgs), lbls)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 5.5) Evaluation on test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            preds = model(imgs).argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(lbls.numpy())\n",
    "\n",
    "    return accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# ─── 6) Run the Optuna study ───────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    print(\"Best accuracy:\", study.best_value)\n",
    "    print(\"Best hyperparameters:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Hyper-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"optuna\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Paths and number of classes\n",
    "# -----------------------------------------------------------------------------\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "num_classes = len(next(os.walk(TRAIN_DIR))[1])\n",
    "print(f\"Detected {num_classes} classes.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Data transforms\n",
    "# -----------------------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Datasets and train/validation split\n",
    "# -----------------------------------------------------------------------------\n",
    "full_train = datasets.ImageFolder(root=TRAIN_DIR, transform=transform)\n",
    "test_ds    = datasets.ImageFolder(root=TEST_DIR,  transform=transform)\n",
    "\n",
    "train_len = int(0.8 * len(full_train))\n",
    "val_len   = len(full_train) - train_len\n",
    "train_ds, val_ds = random_split(full_train, [train_len, val_len])\n",
    "\n",
    "def make_loader(dataset, batch_size, shuffle):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                      num_workers=4, pin_memory=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Define the Optuna-powered CNN\n",
    "# -----------------------------------------------------------------------------\n",
    "class OptunaCNN(nn.Module):\n",
    "    def __init__(self, trial, num_classes, input_shape):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "\n",
    "        in_ch = input_shape[0]\n",
    "        n_conv = trial.suggest_int('n_conv_layers', 1, 4)\n",
    "        for i in range(n_conv):\n",
    "            out_ch = trial.suggest_categorical(f\"conv{i}_out\", [16, 32, 64, 128])\n",
    "            k      = trial.suggest_int(f\"conv{i}_k\", 3, 7, step=2)\n",
    "            p      = trial.suggest_int(f\"conv{i}_pad\", 0, k // 2)\n",
    "            self.convs.append(nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p))\n",
    "\n",
    "            norm_t = trial.suggest_categorical(f\"conv{i}_norm\", ['none', 'batch', 'layer'])\n",
    "            if norm_t == 'batch':\n",
    "                self.norms.append(nn.BatchNorm2d(out_ch))\n",
    "            elif norm_t == 'layer':\n",
    "                self.norms.append(nn.GroupNorm(1, out_ch))\n",
    "            else:\n",
    "                self.norms.append(None)\n",
    "\n",
    "            in_ch = out_ch\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, *input_shape)\n",
    "            for conv, norm in zip(self.convs, self.norms):\n",
    "                x = conv(x)\n",
    "                if norm: x = norm(x)\n",
    "                x = F.relu(x)\n",
    "                x = self.pool(x)\n",
    "            n_flat = x.numel()\n",
    "\n",
    "        self.fcs = nn.ModuleList()\n",
    "        n_fc = trial.suggest_int('n_fc_layers', 1, 3)\n",
    "        in_feat = n_flat\n",
    "        for j in range(n_fc):\n",
    "            out_f = trial.suggest_int(f\"fc{j}_units\", 32, 512, step=32)\n",
    "            self.fcs.append(nn.Linear(in_feat, out_f))\n",
    "            in_feat = out_f\n",
    "\n",
    "        self.output    = nn.Linear(in_feat, num_classes)\n",
    "        self.dropout_p = trial.suggest_uniform('dropout', 0.0, 0.5)\n",
    "        self.act_name  = trial.suggest_categorical('activation', ['relu', 'leaky_relu', 'elu'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = conv(x)\n",
    "            if norm: x = norm(x)\n",
    "            x = getattr(F, self.act_name)(x)  \n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for fc in self.fcs:\n",
    "            x = fc(x)\n",
    "            x = getattr(F, self.act_name)(x)\n",
    "            x = F.dropout(x, p=self.dropout_p, training=self.training)\n",
    "\n",
    "        return self.output(x)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Optuna objective with weight_decay\n",
    "# -----------------------------------------------------------------------------\n",
    "def objective(trial):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # hyperparameters\n",
    "    batch_size   = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    lr           = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
    "    opt_name     = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
    "    epochs       = trial.suggest_int('epochs', 10, 50)\n",
    "    patience     = trial.suggest_int('patience', 3, 7)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = make_loader(train_ds, batch_size, shuffle=True)\n",
    "    val_loader   = make_loader(val_ds,   batch_size, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    sample_img, _ = next(iter(train_loader))\n",
    "    input_shape   = sample_img.shape[1:]\n",
    "    model = OptunaCNN(trial, num_classes=num_classes, input_shape=input_shape).to(device)\n",
    "\n",
    "    # optimizer with weight_decay\n",
    "    if opt_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif opt_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        momentum  = trial.suggest_uniform('momentum', 0.5, 0.9)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr,\n",
    "                              momentum=momentum,\n",
    "                              weight_decay=weight_decay)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_loss = float('inf')\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for imgs, lbls in train_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(imgs), lbls)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for imgs, lbls in val_loader:\n",
    "                imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "                val_loss += criterion(model(imgs), lbls).item()\n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "\n",
    "        trial.report(avg_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "    return best_loss\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Run the Optuna study\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\", pruner=MedianPruner())\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    print(f\"  Loss:   {study.best_value:.4f}\")\n",
    "    print(\"  Params:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0) Paths and num_classes\n",
    "# -------------------------------------------------------------------\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "num_classes = len(next(os.walk(TRAIN_DIR))[1])\n",
    "print(f\"Detected {num_classes} classes.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Transforms & DataLoaders\n",
    "# -------------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=transform)\n",
    "test_ds  = datasets.ImageFolder(TEST_DIR,  transform=transform)\n",
    "\n",
    "batch_size   = 16\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) FixedCNN with dynamic flat_dim\n",
    "# -------------------------------------------------------------------\n",
    "conv_params = [\n",
    "    (128, 3, 0, 'none'),\n",
    "    ( 16, 7, 3, 'layer'),\n",
    "    (128, 7, 3, 'batch'),\n",
    "    ( 16, 7, 3, 'batch'),\n",
    "]\n",
    "fc_units  = [512]\n",
    "dropout_p = 0.05406253916379472\n",
    "\n",
    "class FixedCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # build conv feature extractor\n",
    "        layers = []\n",
    "        in_ch = 3\n",
    "        for out_ch, k, p, norm in conv_params:\n",
    "            layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p))\n",
    "            if norm == 'batch':\n",
    "                layers.append(nn.BatchNorm2d(out_ch))\n",
    "            elif norm == 'layer':\n",
    "                layers.append(nn.GroupNorm(1, out_ch))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            in_ch = out_ch\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "\n",
    "        # determine flattened dimension automatically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 224, 224)\n",
    "            feat  = self.feature_extractor(dummy)\n",
    "            flat_dim = feat.view(1, -1).size(1)\n",
    "\n",
    "        # build classifier head\n",
    "        fc_layers = []\n",
    "        in_feat = flat_dim\n",
    "        for out_feat in fc_units:\n",
    "            fc_layers.append(nn.Linear(in_feat, out_feat))\n",
    "            fc_layers.append(nn.ReLU(inplace=True))\n",
    "            fc_layers.append(nn.Dropout(dropout_p))\n",
    "            in_feat = out_feat\n",
    "\n",
    "        # final output layer\n",
    "        fc_layers.append(nn.Linear(in_feat, num_classes))\n",
    "        self.classifier = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Instantiate, optimizer, criterion\n",
    "# -------------------------------------------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = FixedCNN(num_classes).to(device)\n",
    "optimizer = optim.RMSprop(\n",
    "    model.parameters(),\n",
    "    lr=8.742429747329988e-05,\n",
    "    weight_decay=0.0008288643868674648\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Training loop\n",
    "# -------------------------------------------------------------------\n",
    "epochs = 19\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = 100. * correct / total\n",
    "    print(f\"Epoch {epoch}: Loss = {epoch_loss:.4f}, Acc = {epoch_acc:.2f}%\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Final evaluation on test set\n",
    "# -------------------------------------------------------------------\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "test_acc = accuracy_score(all_labels, all_preds) * 100\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=train_ds.classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pykan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─── 1) Paths & Transforms ────────────────────────────────────────────\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# ─── 2) Datasets & Loaders ───────────────────────────────────────────\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=TEST_DIR,  transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "\n",
    "# ─── 3) Your KAN Backbone Stub ────────────────────────────────────────\n",
    "# Replace this with your actual KAN implementation.\n",
    "class KANBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Example: you might have conv layers + attention blocks here\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # ... more layers / attention ...\n",
    "            nn.Conv2d(64, 512, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)   # [B, 512, H, W]\n",
    "\n",
    "\n",
    "# ─── 4) Full KANModel with Pooling + Classifier ───────────────────────\n",
    "class KANModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone    = KANBackbone()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))  # → [B, 512, 1, 1]\n",
    "        self.classifier  = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)        # [B, 512, H, W]\n",
    "        x = self.global_pool(x)     # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)     # [B, 512]\n",
    "        logits = self.classifier(x) # [B, num_classes]\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ─── 5) Setup device, model, loss, optimizer ─────────────────────────\n",
    "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model     = KANModel(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "# ─── 6) Training & Eval Routines ─────────────────────────────────────\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "\n",
    "# ─── 7) Main Loop with Checkpointing ──────────────────────────────────\n",
    "num_epochs = 25\n",
    "best_acc   = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss,   val_acc   = evaluate(model, test_loader,  criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "          f\" Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # save best\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_kan_model.pth\")\n",
    "\n",
    "print(f\"Best validation accuracy: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─── 1) Enable cuDNN autotuner for faster convolutions ────────────────\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ─── 2) Paths & Transforms ────────────────────────────────────────────\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# ─── 3) Datasets & Loaders ───────────────────────────────────────────\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=TEST_DIR,  transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# ─── 4) KAN Backbone Stub (replace with your real implementation) ─────\n",
    "class KANBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Example conv + attention stub; insert your KAN layers here\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # ... more conv/attention blocks ...\n",
    "            nn.Conv2d(64, 512, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # → [B, 512, H, W]\n",
    "\n",
    "# ─── 5) Full Model with Global Pooling + Classifier ───────────────────\n",
    "class KANModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone    = KANBackbone()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))  # → [B, 512, 1, 1]\n",
    "        self.classifier  = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)        # [B, 512, H, W]\n",
    "        x = self.global_pool(x)     # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)     # [B, 512]\n",
    "        return self.classifier(x)   # [B, num_classes]\n",
    "\n",
    "# ─── 6) Setup Device, Model, Loss, Optimizer, AMP ────────────────────\n",
    "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model     = KANModel(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scaler    = GradScaler()\n",
    "\n",
    "# ─── 7) Training & Evaluation Routines ───────────────────────────────\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, scaler):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():  # mixed-precision forward\n",
    "            outputs = model(imgs)\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()  # scaled backward\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad(), autocast():  # mixed-precision eval\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# ─── 8) Main Loop with Checkpointing & Interrupt Handling ────────────\n",
    "num_epochs = 10\n",
    "best_acc   = 0.0\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, scaler\n",
    "        )\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "              f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_kan_model.pth\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n🛑 Training interrupted. Saving checkpoint to 'interrupted_kan_model.pth'\")\n",
    "    torch.save(model.state_dict(), \"interrupted_kan_model.pth\")\n",
    "    raise\n",
    "\n",
    "print(f\"✅ Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from kan import KAN\n",
    "import time\n",
    "\n",
    "class KANClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        print(\"Initializing feature extractor...\")\n",
    "        \n",
    "        # 1. Feature Extractor\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(mobilenet.children())[:-1])\n",
    "        \n",
    "        # 2. Feature Processing\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc_reduce = nn.Linear(1280, 256)\n",
    "        \n",
    "        # 3. KAN Layer\n",
    "        self.kan = KAN(\n",
    "            width=[256, 64, num_classes],  # [input_dim, hidden_dim, output_dim]\n",
    "            grid=3,\n",
    "            k=2,\n",
    "            noise_scale=0.1,\n",
    "            base_fun=torch.nn.ReLU(),\n",
    "            grid_eps=1.0,\n",
    "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1. Extract features with shape checking\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(f\"Expected 4D input (BxCxHxW), got {x.dim()}D\")\n",
    "        \n",
    "        # 2. Pass through feature extractor\n",
    "        features = self.feature_extractor(x)  # [B, 1280, H', W']\n",
    "        \n",
    "        # 3. Global pooling and reshape\n",
    "        features = self.pool(features)        # [B, 1280, 1, 1]\n",
    "        features = features.view(x.size(0), -1)  # [B, 1280]\n",
    "        \n",
    "        # 4. Dimension reduction and preprocessing\n",
    "        features = self.dropout(features)\n",
    "        features = self.fc_reduce(features)   # [B, 256]\n",
    "        \n",
    "        # 5. KAN expects [batch_size, feature_dim]\n",
    "        # No need for additional unsqueeze since KAN handles the reshaping internally\n",
    "        output = self.kan(features)           # [B, num_classes]\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Training settings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model and move to device\n",
    "model = KANClassifier(num_classes).to(device)\n",
    "\n",
    "# Optimizer with lower learning rate for stability\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Epoch {epoch}: Loss = {avg_loss:.4f}, Acc = {accuracy:.2f}%')\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(lbls.numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Epoch {epoch:2d}/10 — Test Acc: {acc:.4f}\")\n",
    "\n",
    "# Final Report\n",
    "print(\"\\nFinal KAN classification report:\")\n",
    "print(classification_report(all_labels, all_preds, \n",
    "                          target_names=train_dataset.classes, \n",
    "                          digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─── 1) Enable cuDNN autotuner for faster convolutions ────────────────\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ─── 2) Paths & Transforms ────────────────────────────────────────────\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# ─── 3) Datasets & Loaders ───────────────────────────────────────────\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=TEST_DIR,  transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "\n",
    "# ─── 4) Pretrained ResNet-50 Backbone ─────────────────────────────────\n",
    "class PretrainedBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # load a ResNet50 pretrained on ImageNet\n",
    "        backbone = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        # optionally freeze all layers:\n",
    "        # for param in backbone.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # cut off the final fc & avgpool:\n",
    "        self.features = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.out_channels = 2048\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)  # [B, 2048, H', W']\n",
    "\n",
    "\n",
    "# ─── 5) Full Model with Pretrained Backbone ───────────────────────────\n",
    "class KANModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone    = PretrainedBackbone()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))  # → [B, 2048, 1, 1]\n",
    "        self.classifier  = nn.Linear(self.backbone.out_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)        # [B, 2048, H, W]\n",
    "        x = self.global_pool(x)     # [B, 2048, 1, 1]\n",
    "        x = torch.flatten(x, 1)     # [B, 2048]\n",
    "        return self.classifier(x)   # [B, num_classes]\n",
    "\n",
    "\n",
    "# ─── 6) Setup Device, Model, Loss, Optimizer, AMP ────────────────────\n",
    "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model     = KANModel(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scaler    = GradScaler()\n",
    "\n",
    "# ─── 7) Training & Evaluation Routines ───────────────────────────────\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, scaler):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(imgs)\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad(), autocast():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "# ─── 8) Main Loop with Checkpointing & Interrupt Handling ────────────\n",
    "num_epochs = 25\n",
    "best_acc   = 0.0\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, scaler\n",
    "        )\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "              f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_kan_model.pth\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n🛑 Training interrupted. Saving checkpoint to 'interrupted_kan_model.pth'\")\n",
    "    torch.save(model.state_dict(), \"interrupted_kan_model.pth\")\n",
    "    raise\n",
    "\n",
    "print(f\"✅ Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1) Reproducibility + device\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2) Paths\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "# 3) Custom label mapping\n",
    "label_map = {\n",
    "    \"glioma_tumor\":     0,\n",
    "    \"meningioma_tumor\": 1,\n",
    "    \"no_tumor\":         2,\n",
    "    \"pituitary_tumor\":  3\n",
    "}\n",
    "\n",
    "# 4) Transforms: PIL grayscale → Resize → Tensor → repeat → Normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),            # single-channel PIL\n",
    "    transforms.Resize((224, 224)),                         # resize while PIL\n",
    "    transforms.ToTensor(),                                 # now a tensor [1×224×224]\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),        # expand → [3×224×224]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],       # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 5) Subclass ImageFolder to apply your label_map\n",
    "class MappedImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        img, orig_idx = super().__getitem__(index)\n",
    "        classname = self.classes[orig_idx]\n",
    "        mapped_label = label_map[classname]\n",
    "        return img, mapped_label\n",
    "\n",
    "# 6) Datasets & train/val split\n",
    "full_train = MappedImageFolder(root=TRAIN_DIR, transform=transform)\n",
    "test_ds    = MappedImageFolder(root=TEST_DIR,  transform=transform)\n",
    "\n",
    "train_len = int(0.8 * len(full_train))\n",
    "val_len   = len(full_train) - train_len\n",
    "train_ds, val_ds = random_split(full_train, [train_len, val_len])\n",
    "\n",
    "# 7) Dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "\n",
    "# 8) Number of classes\n",
    "num_classes = len(label_map)\n",
    "print(f\"Using {num_classes} classes with mapping: {label_map}\")\n",
    "\n",
    "# 9) Model: fine-tuned ResNet50\n",
    "class ResNet50Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        in_feats = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_feats, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = ResNet50Model(num_classes).to(device)\n",
    "\n",
    "# 10) Loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 11) Training and evaluation functions\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    return 100. * correct / total, all_preds, all_labels\n",
    "\n",
    "# 12) Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_acc, _, _ = eval_epoch(model, val_loader)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} — \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# 13) Final test evaluation\n",
    "test_acc, preds, labels = eval_epoch(model, test_loader)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds, target_names=list(label_map.keys())))\n",
    "\n",
    "# 14) Save the fine-tuned model\n",
    "torch.save(model.state_dict(), \"tumor_resnet50_mapped.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) Reproducibility & device\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2) Paths to your tumor MRI folders\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR  = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "\n",
    "# 3) Custom label mapping\n",
    "label_map = {\n",
    "    \"glioma_tumor\":     0,\n",
    "    \"meningioma_tumor\": 1,\n",
    "    \"no_tumor\":         2,\n",
    "    \"pituitary_tumor\":  3\n",
    "}\n",
    "\n",
    "# 4) Transforms: PIL grayscale → Resize → Tensor → repeat → Normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),    # load as single‐channel PIL image\n",
    "    transforms.Resize((224, 224)),                  # resize while still PIL\n",
    "    transforms.ToTensor(),                          # to tensor [1×224×224]\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)), # expand → [3×224×224]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet statistics\n",
    "])\n",
    "\n",
    "# 5) Subclass ImageFolder to apply your custom label_map\n",
    "class MappedImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        img, orig_idx = super().__getitem__(index)\n",
    "        classname     = self.classes[orig_idx]\n",
    "        mapped_label  = label_map[classname]\n",
    "        return img, mapped_label\n",
    "\n",
    "# 6) Build datasets & split train→val\n",
    "full_train = MappedImageFolder(root=TRAIN_DIR, transform=transform)\n",
    "test_ds    = MappedImageFolder(root=TEST_DIR,  transform=transform)\n",
    "\n",
    "train_len = int(0.8 * len(full_train))\n",
    "val_len   = len(full_train) - train_len\n",
    "train_ds, val_ds = random_split(full_train, [train_len, val_len])\n",
    "\n",
    "# 7) DataLoaders\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "\n",
    "# 8) Number of classes\n",
    "num_classes = len(label_map)\n",
    "print(f\"Detected {num_classes} classes: {full_train.classes}\")\n",
    "\n",
    "# 9) Model Definitions\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*28*28,256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        base = models.resnet50(pretrained=True)\n",
    "        # ResNet50 features (drop the final fc)\n",
    "        self.resnet_feat = nn.Sequential(*list(base.children())[:-1])\n",
    "        # Simple CNN features\n",
    "        self.cnn_feat = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        # determine cnn feature dim\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1,3,224,224)\n",
    "            cnn_dim = self.cnn_feat(dummy).shape[1]\n",
    "        # fusion classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048 + cnn_dim, 512),\n",
    "            nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        f1 = self.resnet_feat(x).view(x.size(0), -1)\n",
    "        f2 = self.cnn_feat(x)\n",
    "        return self.classifier(torch.cat([f1, f2], dim=1))\n",
    "\n",
    "# 10) Training & evaluation utilities\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_correct += preds.eq(labels).sum().item()\n",
    "        total_samples += imgs.size(0)\n",
    "    return total_loss/total_samples, total_correct/total_samples\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=list(label_map.keys()))\n",
    "    return acc, report\n",
    "\n",
    "# 11) Train & compare models\n",
    "models_to_train = {\n",
    "    'ResNet50':  ResNet50Classifier(num_classes),\n",
    "    'SimpleCNN': SimpleCNN(num_classes),\n",
    "    'Fusion':    FusionModel(num_classes)\n",
    "}\n",
    "\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "num_epochs = 10\n",
    "results    = {}\n",
    "\n",
    "for name, model in models_to_train.items():\n",
    "    print(f\"\\n=== Training {name} for {num_epochs} epochs ===\")\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        loss, acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        print(f\"{name} Epoch {epoch}/{num_epochs} — Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "    test_acc, test_report = evaluate(model, test_loader)\n",
    "    results[name] = (test_acc, test_report)\n",
    "    print(f\"\\n{name} Final Test Acc: {test_acc:.4f}\")\n",
    "    print(test_report)\n",
    "\n",
    "# 12) Summary of results\n",
    "print(\"\\n=== Summary of Test Accuracies ===\")\n",
    "for name, (acc, _) in results.items():\n",
    "    print(f\"{name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "\n",
    "# Paths and device\n",
    "TRAIN_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Training\"\n",
    "TEST_DIR = \"/home/mhs/thesis/Brain MRI ND-5 Dataset/tumordata/Testing\"\n",
    "RAD_NPZ = \"/home/mhs/thesis/radiomics_dataset.npz\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load radiomics data\n",
    "rad = np.load(RAD_NPZ)\n",
    "X_train_rad, y_train = rad['X_train'], rad['y_train']\n",
    "X_test_rad, y_test = rad['X_test'], rad['y_test']\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f\"Detected {num_classes} classes in radiomics data.\")\n",
    "print(\"X_train_rad shape:\", X_train_rad.shape)\n",
    "print(\"X_test_rad shape:\", X_test_rad.shape)\n",
    "\n",
    "# Transforms for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom Dataset to pair images with radiomics features\n",
    "class PairedDataset(Dataset):\n",
    "    def __init__(self, image_dataset, radiomics_features, labels):\n",
    "        self.image_dataset = image_dataset\n",
    "        self.radiomics_features = radiomics_features\n",
    "        self.labels = labels\n",
    "        assert len(image_dataset) == len(radiomics_features) == len(labels), \"Mismatched dataset lengths\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, img_label = self.image_dataset[idx]\n",
    "        rad_features = torch.tensor(self.radiomics_features[idx], dtype=torch.float32)\n",
    "        label = self.labels[idx]\n",
    "        return img, rad_features, label\n",
    "\n",
    "# Load image datasets\n",
    "train_image_ds = datasets.ImageFolder(TRAIN_DIR, transform=transform)\n",
    "test_image_ds = datasets.ImageFolder(TEST_DIR, transform=transform)\n",
    "\n",
    "# Create paired datasets\n",
    "train_dataset = PairedDataset(train_image_ds, X_train_rad, y_train)\n",
    "test_dataset = PairedDataset(test_image_ds, X_test_rad, y_test)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# CNN Model (same as provided)\n",
    "conv_params = [\n",
    "    (128, 3, 0, 'none'),\n",
    "    (16, 7, 3, 'layer'),\n",
    "    (128, 7, 3, 'batch'),\n",
    "    (16, 7, 3, 'batch'),\n",
    "]\n",
    "fc_units = [512]\n",
    "dropout_p = 0.05406253916379472\n",
    "\n",
    "class FixedCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_ch = 3\n",
    "        for out_ch, k, p, norm in conv_params:\n",
    "            layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p))\n",
    "            if norm == 'batch':\n",
    "                layers.append(nn.BatchNorm2d(out_ch))\n",
    "            elif norm == 'layer':\n",
    "                layers.append(nn.GroupNorm(1, out_ch))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            in_ch = out_ch\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 224, 224)\n",
    "            feat = self.feature_extractor(dummy)\n",
    "            flat_dim = feat.view(1, -1).size(1)\n",
    "        fc_layers = []\n",
    "        in_feat = flat_dim\n",
    "        for out_feat in fc_units:\n",
    "            fc_layers.append(nn.Linear(in_feat, out_feat))\n",
    "            fc_layers.append(nn.ReLU(inplace=True))\n",
    "            fc_layers.append(nn.Dropout(dropout_p))\n",
    "            in_feat = out_feat\n",
    "        fc_layers.append(nn.Linear(in_feat, num_classes))\n",
    "        self.classifier = nn.Sequential(*fc_layers)\n",
    "        self.flat_dim = flat_dim\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = self.feature_extractor(x)\n",
    "        x_flat = x.view(x.size(0), -1)\n",
    "        if return_features:\n",
    "            return x_flat\n",
    "        return self.classifier(x_flat)\n",
    "\n",
    "# Instantiate and load pre-trained CNN\n",
    "cnn_model = FixedCNN(num_classes).to(device)\n",
    "optimizer = optim.RMSprop(\n",
    "    cnn_model.parameters(),\n",
    "    lr=8.742429747329988e-05,\n",
    "    weight_decay=0.0008288643868674648\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train CNN (or assume pre-trained weights are loaded)\n",
    "epochs = 19\n",
    "for epoch in range(1, epochs + 1):\n",
    "    cnn_model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, _, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch {epoch}: Loss = {epoch_loss:.4f}, Acc = {epoch_acc:.2f}%\")\n",
    "\n",
    "# Extract CNN features for training and test sets\n",
    "cnn_model.eval()\n",
    "train_cnn_features = []\n",
    "train_labels = []\n",
    "test_cnn_features = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, _, labels in tqdm(train_loader, desc=\"Extracting train CNN features\"):\n",
    "        imgs = imgs.to(device)\n",
    "        features = cnn_model(imgs, return_features=True).cpu().numpy()\n",
    "        train_cnn_features.append(features)\n",
    "        train_labels.append(labels.numpy())\n",
    "    for imgs, _, labels in tqdm(test_loader, desc=\"Extracting test CNN features\"):\n",
    "        imgs = imgs.to(device)\n",
    "        features = cnn_model(imgs, return_features=True).cpu().numpy()\n",
    "        test_cnn_features.append(features)\n",
    "        test_labels.append(labels.numpy())\n",
    "\n",
    "train_cnn_features = np.concatenate(train_cnn_features, axis=0)\n",
    "test_cnn_features = np.concatenate(test_cnn_features, axis=0)\n",
    "train_labels = np.concatenate(train_labels, axis=0)\n",
    "test_labels = np.concatenate(test_labels, axis=0)\n",
    "print(\"Train CNN features shape:\", train_cnn_features.shape)\n",
    "print(\"Test CNN features shape:\", test_cnn_features.shape)\n",
    "\n",
    "# Normalize radiomics features for compatibility\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_rad_scaled = scaler.fit_transform(X_train_rad)\n",
    "X_test_rad_scaled = scaler.transform(X_test_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load shared setup (assumed to be executed)\n",
    "# Variables available: train_cnn_features, test_cnn_features, X_train_rad_scaled, X_test_rad_scaled, train_labels, test_labels\n",
    "\n",
    "# Concatenate CNN and radiomics features\n",
    "train_fused_features = np.concatenate([train_cnn_features, X_train_rad_scaled], axis=1)\n",
    "test_fused_features = np.concatenate([test_cnn_features, X_test_rad_scaled], axis=1)\n",
    "print(\"Train fused features shape:\", train_fused_features.shape)\n",
    "print(\"Test fused features shape:\", test_fused_features.shape)\n",
    "\n",
    "# Train Random Forest on fused features\n",
    "rf_fusion = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_fusion.fit(train_fused_features, train_labels)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_fusion = rf_fusion.predict(test_fused_features)\n",
    "test_acc = accuracy_score(test_labels, y_pred_fusion) * 100\n",
    "print(f\"\\nFeature-Level Fusion (Random Forest) Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred_fusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load shared setup (assumed to be executed)\n",
    "# Variables available: cnn_model, train_loader, test_loader, X_train_rad_scaled, X_test_rad_scaled, train_labels, test_labels\n",
    "\n",
    "# Train Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_rad_scaled, train_labels)\n",
    "\n",
    "# Get CNN probabilities\n",
    "cnn_model.eval()\n",
    "train_cnn_probs = []\n",
    "test_cnn_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, _, _ in tqdm(train_loader, desc=\"Computing train CNN probs\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = torch.softmax(cnn_model(imgs), dim=1).cpu().numpy()\n",
    "        train_cnn_probs.append(outputs)\n",
    "    for imgs, _, _ in tqdm(test_loader, desc=\"Computing test CNN probs\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = torch.softmax(cnn_model(imgs), dim=1).cpu().numpy()\n",
    "        test_cnn_probs.append(outputs)\n",
    "\n",
    "train_cnn_probs = np.concatenate(train_cnn_probs, axis=0)\n",
    "test_cnn_probs = np.concatenate(test_cnn_probs, axis=0)\n",
    "\n",
    "# Get Random Forest probabilities\n",
    "train_rf_probs = rf_clf.predict_proba(X_train_rad_scaled)\n",
    "test_rf_probs = rf_clf.predict_proba(X_test_rad_scaled)\n",
    "\n",
    "# Weighted Averaging (weights based on accuracies: CNN 93%, RF 76%)\n",
    "w_cnn, w_rf = 0.7, 0.3\n",
    "train_fused_probs = w_cnn * train_cnn_probs + w_rf * train_rf_probs\n",
    "test_fused_probs = w_cnn * test_cnn_probs + w_rf * test_rf_probs\n",
    "y_pred_weighted = np.argmax(test_fused_probs, axis=1)\n",
    "test_acc_weighted = accuracy_score(test_labels, y_pred_weighted) * 100\n",
    "print(f\"\\nDecision-Level Fusion (Weighted Averaging) Test Accuracy: {test_acc_weighted:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred_weighted))\n",
    "\n",
    "# Stacking with Logistic Regression\n",
    "train_stack_features = np.concatenate([train_cnn_probs, train_rf_probs], axis=1)\n",
    "test_stack_features = np.concatenate([test_cnn_probs, test_rf_probs], axis=1)\n",
    "meta_classifier = LogisticRegression(multi_class='multinomial', random_state=42)\n",
    "meta_classifier.fit(train_stack_features, train_labels)\n",
    "y_pred_stack = meta_classifier.predict(test_stack_features)\n",
    "test_acc_stack = accuracy_score(test_labels, y_pred_stack) * 100\n",
    "print(f\"\\nDecision-Level Fusion (Stacking) Test Accuracy: {test_acc_stack:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load shared setup (assumed to be executed)\n",
    "# Variables available: cnn_model, train_loader, test_loader, num_classes, device, criterion\n",
    "\n",
    "# Define Hybrid Fusion Model\n",
    "class HybridFusionModel(nn.Module):\n",
    "    def __init__(self, cnn_model, radiomics_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.cnn = cnn_model\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False  # Freeze CNN weights\n",
    "        self.cnn_feature_dim = cnn_model.flat_dim\n",
    "        self.fc_radiomics = nn.Linear(radiomics_dim, 128)\n",
    "        self.fc_fused = nn.Sequential(\n",
    "            nn.Linear(self.cnn_feature_dim + 128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs, rad_features):\n",
    "        cnn_features = self.cnn(imgs, return_features=True)\n",
    "        rad_features = torch.relu(self.fc_radiomics(rad_features))\n",
    "        fused = torch.cat([cnn_features, rad_features], dim=1)\n",
    "        return self.fc_fused(fused)\n",
    "\n",
    "# Instantiate model\n",
    "radiomics_dim = X_train_rad_scaled.shape[1]\n",
    "hybrid_model = HybridFusionModel(cnn_model, radiomics_dim, num_classes).to(device)\n",
    "optimizer = optim.Adam(hybrid_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    hybrid_model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, rad_features, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        imgs, rad_features, labels = imgs.to(device), rad_features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = hybrid_model(imgs, rad_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch {epoch}: Loss = {epoch_loss:.4f}, Acc = {epoch_acc:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "hybrid_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, rad_features, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs, rad_features = imgs.to(device), rad_features.to(device)\n",
    "        outputs = hybrid_model(imgs, rad_features)\n",
    "        preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "test_acc = accuracy_score(all_labels, all_preds) * 100\n",
    "print(f\"\\nHybrid Fusion Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load shared setup (assumed to be executed)\n",
    "# Variables available: train_cnn_features, test_cnn_features, X_train_rad_scaled, X_test_rad_scaled, train_labels, test_labels\n",
    "\n",
    "# Concatenate CNN features with radiomics features\n",
    "train_cascade_features = np.concatenate([train_cnn_features, X_train_rad_scaled], axis=1)\n",
    "test_cascade_features = np.concatenate([test_cnn_features, X_test_rad_scaled], axis=1)\n",
    "print(\"Train cascade features shape:\", train_cascade_features.shape)\n",
    "print(\"Test cascade features shape:\", test_cascade_features.shape)\n",
    "\n",
    "# Train Random Forest on cascaded features\n",
    "rf_cascade = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_cascade.fit(train_cascade_features, train_labels)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_cascade = rf_cascade.predict(test_cascade_features)\n",
    "test_acc = accuracy_score(test_labels, y_pred_cascade) * 100\n",
    "print(f\"\\nCascade Fusion (CNN -> RF) Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred_cascade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load shared setup (assumed to be executed)\n",
    "# Variables available: cnn_model, train_loader, test_loader, num_classes, device, criterion\n",
    "\n",
    "# Define Attention Fusion Model\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    def __init__(self, cnn_model, radiomics_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.cnn = cnn_model\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False  # Freeze CNN weights\n",
    "        self.cnn_feature_dim = cnn_model.flat_dim\n",
    "        self.fc_radiomics = nn.Linear(radiomics_dim, 128)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.cnn_feature_dim + 128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_fused = nn.Sequential(\n",
    "            nn.Linear(self.cnn_feature_dim + 128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs, rad_features):\n",
    "        cnn_features = self.cnn(imgs, return_features=True)\n",
    "        rad_features = torch.relu(self.fc_radiomics(rad_features))\n",
    "        combined = torch.cat([cnn_features, rad_features], dim=1)\n",
    "        attn_weights = self.attention(combined)\n",
    "        weighted_features = combined * attn_weights\n",
    "        return self.fc_fused(weighted_features)\n",
    "\n",
    "# Instantiate model\n",
    "radiomics_dim = X_train_rad_scaled.shape[1]\n",
    "attention_model = AttentionFusionModel(cnn_model, radiomics_dim, num_classes).to(device)\n",
    "optimizer = optim.Adam(attention_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    attention_model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, rad_features, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        imgs, rad_features, labels = imgs.to(device), rad_features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = attention_model(imgs, rad_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch {epoch}: Loss = {epoch_loss:.4f}, Acc = {epoch_acc:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "attention_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, rad_features, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs, rad_features = imgs.to(device), rad_features.to(device)\n",
    "        outputs = attention_model(imgs, rad_features)\n",
    "        preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "test_acc = accuracy_score(all_labels, all_preds) * 100\n",
    "print(f\"\\nAttention-Based Fusion Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7461040,
     "sourceId": 11872280,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7462089,
     "sourceId": 11873781,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
